{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate data for awake monkey "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from scipy.stats import sem\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "import os, json\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "\n",
    "from ksd.utils.noise_utils import extract_rawdata\n",
    "from ksd import KSD\n",
    "\n",
    "print(KSD.__version__, datetime.today())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FIGURE_DATA_PATH = \".../paper/figure_data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 运行KSD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 分别运行\n",
    "\n",
    "+ 钨丝到PI 161um\n",
    "+ PI到第一个位点 130um"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "querystr = \"(group=='good')&(fr>0.1)&(imp<2)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "postprocess_directory = \"...projects/Awake0915/25mm_task1_opsNT32768_Th99/kilosort3_7_mc - jhl1209\"\n",
    "\n",
    "ksd_instance = KSD(\n",
    "    postprocess_directory,\n",
    "    area_names=[\n",
    "        \"hip\",\n",
    "        \"cwm1\",\n",
    "        \"cortex1\",\n",
    "    ],\n",
    "    dist_division=[\n",
    "        0,\n",
    "        2.81,\n",
    "        13.0,\n",
    "        16.0,\n",
    "    ],\n",
    "    phy_subset_dir=os.path.join(postprocess_directory, \"subset_onlyfilter\"),\n",
    "    querystr=querystr,\n",
    "    dat_path=os.path.join(postprocess_directory, \"..\", \"temp_filtered.dat\"),\n",
    "    imp_threshold=2,\n",
    "    amp_threshold=20,\n",
    "    subfolder=\"ksd_v1.9\",\n",
    "    mmap_mode=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ksd_instance.cluster_count,ksd_instance.info.query('isi==0').cluster_id.count()\n",
    "# (314, 281)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integration with behavioral data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get trial info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_codes_const = [9, 50, 51, 52, 60, 61, 62, 63, 70, 18]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "codes = pd.read_csv(\n",
    "    \"...projects/Awake0915/.codes/25mm_task1_230915_112233_codes_curated.csv\"\n",
    ")\n",
    "\n",
    "codes[\"trial\"] = -1\n",
    "for n, (trial_start_code_id, trial_end_code_id) in enumerate(\n",
    "    zip(codes.query(\"code==9\").index, codes.query(\"code==18\").index)\n",
    "):\n",
    "    codes.loc[trial_start_code_id:trial_end_code_id, \"trial\"] = n + 1\n",
    "\n",
    "codes.drop(\n",
    "    index=codes[codes.trial == -1].index, inplace=True\n",
    ")  # delete incomplete trials\n",
    "\n",
    "failed_trials = codes[codes.code == 17].trial.unique()\n",
    "codes.drop(\n",
    "    index=codes.query(\"trial in @failed_trials\").index, inplace=True\n",
    ")  # delete failed trials\n",
    "trial_info = pd.DataFrame(\n",
    "    codes.groupby(\"code\")\n",
    "    .apply(lambda x: x.t.values)[trial_codes_const]\n",
    "    .values.tolist(),\n",
    "    index=trial_codes_const,\n",
    "    columns=codes.trial.unique(),\n",
    ").T\n",
    "trial_info.index.rename(\"trial\", inplace=True)\n",
    "trial_info[\"position\"] = codes.groupby(\"trial\").code.apply(\n",
    "    lambda x: x[x > 200].values[0] - 201\n",
    ")\n",
    "trial_info[\"stimuli\"] = codes.groupby(\"trial\").code.apply(\n",
    "    lambda x: x[(x > 100) & (x < 200)].values[0] - 101\n",
    ")\n",
    "trial_info[\"category\"] = trial_info[\"stimuli\"] // 5\n",
    "trial_info[\"category_name\"] = trial_info.category.apply(\n",
    "    lambda x: \"geom\" if x == 0 else \"plant\" if x == 1 else \"face\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_info[\"RT1\"] = trial_info[51] - 0.15\n",
    "trial_info[\"RT2\"] = trial_info[61] - 0.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RT1 = trial_info[51] - trial_info[50] - 0.15\n",
    "RT2 = trial_info[61] - trial_info[52] - 0.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extremeRT2 = RT2[RT2 > RT2.mean() + 3 * RT2.std()].index\n",
    "trial_info.drop(index=extremeRT2, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RT1 = trial_info[51] - trial_info[50] - 0.15\n",
    "RT2 = trial_info[61] - trial_info[60] - 0.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RT2.mean(), RT2.std()  # (0.2044207312016793, 0.02902067076651561)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate ITI 4.222207628474572 1.6135906554947996\n",
    "print(\n",
    "    (trial_info[50].values[1:] - trial_info[70].values[:-1]).mean(),\n",
    "    (trial_info[50].values[1:] - trial_info[70].values[:-1]).std(),\n",
    ")\n",
    "# calculate avarage running time of a trial 2.125796077369753 0.4868473737712269\n",
    "print(\n",
    "    (trial_info[70].values - trial_info[50]).mean(),\n",
    "    (trial_info[70].values - trial_info[50]).std(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relative_time = lambda code: [\n",
    "    np.mean(trial_info[each_code] - trial_info[code])\n",
    "    for each_code in [50, \"RT1\", 60, \"RT2\", 62, 63, 70]\n",
    "]\n",
    "relative_time_std = lambda code: [\n",
    "    np.std(trial_info[each_code] - trial_info[code])\n",
    "    for each_code in [50, \"RT1\", 60, \"RT2\", 62, 63, 70]\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculation of Baseline firing rate \n",
    "\n",
    "Definition of Baseline : the average firing rate within 2000-1000ms before the fixation point appears."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_baseline(clid, code=50, window_start=-2, window_end=-1):\n",
    "    baseline_window_start = trial_info[code] + window_start\n",
    "    baseline_window_end = trial_info[code] + window_end\n",
    "    spike_times_for_this_cluster = ksd_instance.get_spike_train(clid)\n",
    "\n",
    "    spike_times_in_window = []\n",
    "    for s, e in zip(baseline_window_start, baseline_window_end):\n",
    "        spike_times_in_window.extend(\n",
    "            spike_times_for_this_cluster[\n",
    "                (spike_times_for_this_cluster > s) & (spike_times_for_this_cluster < e)\n",
    "            ]\n",
    "        )\n",
    "    return len(spike_times_in_window) / (window_end - window_start) / len(trial_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ksd_instance.info[\"fr_baseline\"] = ksd_instance.info.cluster_id.apply(calc_baseline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 5d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_waveforms_per_10trials(\n",
    "    clid, tbefore=41, tafter=41, n_spikes=100, ref=\"mch\"\n",
    "):\n",
    "    assert ref in [\"mch\", \"ch\"]\n",
    "    assert os.path.exists(ksd_instance.dat_path)\n",
    "\n",
    "    refch = ksd_instance.get_attr(ref, clid)\n",
    "\n",
    "    trial_timings = [\n",
    "        0,\n",
    "        *[trial_info.iloc[i][18] for i in [*range(10, 119, 10), 118]],\n",
    "    ]  # 0-10,10-20,...,100-110,110-119\n",
    "\n",
    "    st_for_each_10trials = [\n",
    "        ksd_instance.spike_times_r[\n",
    "            (ksd_instance.spike_clusters == clid)\n",
    "            & (ksd_instance.spike_times_r > trial_timings[i])\n",
    "            & (ksd_instance.spike_times_r < trial_timings[i + 1])\n",
    "        ]\n",
    "        - tbefore / ksd_instance.sample_rate\n",
    "        for i in range(len(trial_timings) - 1)\n",
    "    ]\n",
    "\n",
    "    waveforms = []\n",
    "    mean_waveforms = []\n",
    "\n",
    "    for st in tqdm(st_for_each_10trials):\n",
    "        waveforms_in_this_trial = np.zeros((len(st), tbefore + tafter))\n",
    "        for n, each_st in enumerate(st):\n",
    "            waveforms_in_this_trial[n] = extract_rawdata(\n",
    "                ksd_instance.dat_path,\n",
    "                skip=each_st,\n",
    "                window=(tbefore + tafter) / ksd_instance.sample_rate,\n",
    "                sample_rate=ksd_instance.sample_rate,\n",
    "                n_channels=ksd_instance.channel_count,\n",
    "            )[:, refch].ravel()\n",
    "        waveforms.append(waveforms_in_this_trial)\n",
    "        mean_waveforms.append(waveforms_in_this_trial.mean(axis=0))\n",
    "\n",
    "    return waveforms, mean_waveforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, mwfs = extract_waveforms_per_10trials(3238)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(FIGURE_DATA_PATH + \"fig5/fig5d.json\", \"w\") as fp:\n",
    "    json.dump([mwf.tolist() for mwf in mwfs], fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 5e Upper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spike_times_per_trial(st, sc, clid, code, t_before, t_after):\n",
    "    _spike_time_relative = []\n",
    "    event_count = trial_info[code].__len__()  # codes.query('code==@code').t.count()\n",
    "    for t in trial_info[code]:\n",
    "        _spike_time_relative.append(\n",
    "            st[\n",
    "                (sc == clid)\n",
    "                & (st > t - t_before)\n",
    "                & (ksd_instance.spike_times_r < t + t_after)\n",
    "            ]\n",
    "            - t\n",
    "        )\n",
    "    return _spike_time_relative, event_count\n",
    "\n",
    "\n",
    "def get_spike_times_per_trial_groupby(by, st, sc, clid, code, t_before, t_after):\n",
    "    # 23.11.9, for replacement of `get_spike_times_per_trial_per_category`\n",
    "    # 23.12.12, add trial_ids\n",
    "    results = []\n",
    "    for this_group in sorted(trial_info[by].unique()):\n",
    "        _spike_time_relative = []\n",
    "        trial_ids = trial_info[trial_info[by] == this_group].index.tolist()\n",
    "        event_count = trial_ids.__len__()\n",
    "        for t in trial_info[trial_info[by] == this_group][code]:\n",
    "            _spike_time_relative.append(\n",
    "                st[\n",
    "                    (sc == clid)\n",
    "                    & (st > t - t_before)\n",
    "                    & (ksd_instance.spike_times_r < t + t_after)\n",
    "                ]\n",
    "                - t\n",
    "            )\n",
    "        results.append(\n",
    "            {\n",
    "                by: this_group,\n",
    "                \"spike_time_relative\": _spike_time_relative,\n",
    "                \"event_count\": event_count,\n",
    "                \"trial_ids\": trial_ids,\n",
    "            }\n",
    "        )\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig5e_stdata = get_spike_times_per_trial_groupby(\n",
    "    \"category_name\",\n",
    "    ksd_instance.spike_times_r,\n",
    "    ksd_instance.spike_clusters,\n",
    "    3238,\n",
    "    \"RT2\",\n",
    "    2,\n",
    "    2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(fig5e_stdata).to_json(\n",
    "    FIGURE_DATA_PATH + \"/fig5/fig5e_upper.json\", orient=\"records\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 5e Lower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def swtimes(start, end, window, step):\n",
    "    return np.arange((start + window / 2), (end - window / 2), step)\n",
    "\n",
    "\n",
    "def swfr(st, start, end, window, step):\n",
    "    central_ts = swtimes(start, end, window, step)\n",
    "    return (\n",
    "        central_ts,\n",
    "        np.array(\n",
    "            [\n",
    "                len(\n",
    "                    st[\n",
    "                        (st > (central_t - window / 2))\n",
    "                        & (st < (central_t + window / 2))\n",
    "                    ]\n",
    "                )\n",
    "                for central_t in central_ts\n",
    "            ]\n",
    "        )\n",
    "        / window,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fig5el_data(\n",
    "    by=\"category_name\",\n",
    "    clid=3238,\n",
    "    code=\"RT2\",\n",
    "    tbefore=2,\n",
    "    tafter=2,\n",
    "    window=0.02,\n",
    "    step=0.02,\n",
    "    sigma=3,\n",
    "):\n",
    "    # get spike times\n",
    "    stdata = get_spike_times_per_trial_groupby(\n",
    "        by,\n",
    "        ksd_instance.spike_times_r,\n",
    "        ksd_instance.spike_clusters,\n",
    "        clid,\n",
    "        code,\n",
    "        tbefore,\n",
    "        tafter,\n",
    "    )\n",
    "    times = swtimes(-tbefore, tafter, window, step)\n",
    "    plot_data = []\n",
    "    swfr_max = -1\n",
    "    for each_group_stdata in stdata:\n",
    "        # compute sliding window firing rates\n",
    "        swfrs = np.array(\n",
    "            [\n",
    "                swfr(each_spike_time_relative, -tbefore, tafter, window, step)[1]\n",
    "                for each_spike_time_relative in each_group_stdata[\"spike_time_relative\"]\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        # compute mean and standard error of the mean\n",
    "        if sigma > 0:\n",
    "            swfr_mean = gaussian_filter1d(np.mean(swfrs, axis=0), sigma=sigma)\n",
    "            error = gaussian_filter1d(sem(swfrs, axis=0), sigma=sigma)\n",
    "        else:\n",
    "            swfr_mean = np.mean(swfrs, axis=0)\n",
    "            error = sem(swfrs, axis=0)\n",
    "\n",
    "        if swfr_max < swfr_mean.max():\n",
    "            swfr_max = swfr_mean.max()\n",
    "        plot_data.append(\n",
    "            {\n",
    "                \"group\": each_group_stdata[by],\n",
    "                \"trial_ids\": each_group_stdata[\"trial_ids\"],\n",
    "                \"swtimes\": times,\n",
    "                \"swfrs\": swfrs,\n",
    "                \"error\": error,\n",
    "                \"swfr_mean\": swfr_mean,\n",
    "            }\n",
    "        )\n",
    "    return plot_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig5el_data = get_fig5el_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(fig5el_data).to_json(\n",
    "    FIGURE_DATA_PATH + \"/fig5/fig5e_lower.json\", orient=\"records\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "phy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
